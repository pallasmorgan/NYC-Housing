# -*- coding: utf-8 -*-
"""NYCPrice

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14NrIznwObZW4hnedvlRl7kyBWHqExGYR

#Clustering for Enhanced NYC Housing Price Prediction

*   List item

*   List item
*   List item


*   List item

Morgan Pallas: Pallasmv@g.cofc.edu

Jack Keim: Keimjm@g.cofc.edu
"""

# General Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Sci-Kit Learn Imports
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler, StandardScaler
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, silhouette_score

# Further Imports
from scipy.stats import ttest_rel

### LOAD DATASET

og_df = pd.read_csv('NY-House-Dataset.csv')
data = og_df.copy()
data.head()

data.describe()

data.info()

data.columns

### CLEAN AND TRANSFORM DATA

# Map towns to boroughs by ZIP code
def map_borough(state_value):
    # Split the string by comma and get the last part, which contains the ZIP code
    try:
        zip_code = state_value.split(', ')[-1].split(' ')[-1]
        # Manhattan ZIP codes start with 100
        if zip_code.startswith('100'):
            return 'Manhattan'
        # Bronx ZIP codes start with 104
        elif zip_code.startswith('104'):
            return 'Bronx'
        # Brooklyn ZIP codes start with 112
        elif zip_code.startswith('112'):
            return 'Brooklyn'
        # Queens ZIP codes start with 111, 113, 114, 116
        elif zip_code.startswith(('111', '113', '114', '116')):
            return 'Queens'
        # Staten Island ZIP codes start with 103
        elif zip_code.startswith('103'):
            return 'Staten Island'
        else:
            return 'Other'  # In case some ZIP codes don't match
    except:
        return 'Other'  # Handle any unexpected format

def extract_zip_code(df):
    # Extract the ZIP code by splitting the string using ', ' and space
    df['ZIP_CODE'] = df['STATE'].apply(lambda x: x.split(', ')[-1].split(' ')[-1] if pd.notnull(x) else 'Unknown')
    return df

data['BOROUGH'] = data['STATE'].apply(map_borough)
data = extract_zip_code(data)

# One-hot encode the 'TYPE' and 'STATE', 'BOROUGH' columns
data = pd.get_dummies(data, columns=['TYPE', 'BOROUGH'], drop_first=True)

# drop redundant columns form root data
data = data.drop(columns=['STATE', 'MAIN_ADDRESS', 'FORMATTED_ADDRESS', 'LONG_NAME'])
data.head()

### PLOT NUMERICAL DATA FEATURE DISTRIBUTIONS

# Set up the plotting environment
plt.figure(figsize=(12, 22))

# Numerical columns to visualize future distributions
numerical_columns = ['BEDS', 'BATH', 'PROPERTYSQFT', 'LATITUDE', 'LONGITUDE', 'ZIP_CODE']

# Loop through the columns and plot their distributions
for i, col in enumerate(numerical_columns, 1):
    plt.subplot(4, 2, i)
    sns.histplot(data[col], kde=True, bins=30, color='blue')
    plt.xlabel(col)
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

### CREATE INITIAL SUPERVISED LEARNING MODEL DF

data = data.drop(columns=[
    'BROKERTITLE', 'ADDRESS', 'ADMINISTRATIVE_AREA_LEVEL_2',
    'STREET_NAME', 'LOCALITY', 'SUBLOCALITY',
  ])
data.head()

### SCALE NUMERICAL DATA

# Initialize scalers
robust_scaler = RobustScaler()
standard_scaler = StandardScaler()

# Convert ZIP_CODE to numeric
data['ZIP_CODE'] = pd.to_numeric(data['ZIP_CODE'], errors='coerce')

# Log-transform skewed columns (add 1 to avoid log(0))
data['PROPERTYSQFT_LOG'] = np.log1p(data['PROPERTYSQFT'])
data['BATH_LOG'] = np.log1p(data['BATH'])

# Apply RobustScaler to count-type or high-outlier columns
data[['BEDS_SCALED', 'ZIP_CODE_SCALED']] = robust_scaler.fit_transform(data[['BEDS', 'ZIP_CODE']])

# Apply RobustScaler to log-transformed skewed columns
data[['PROPERTYSQFT_SCALED', 'BATH_SCALED']] = robust_scaler.fit_transform(
    data[['PROPERTYSQFT_LOG', 'BATH_LOG']]
)

# Apply StandardScaler to geographical columns
data[['LATITUDE_SCALED', 'LONGITUDE_SCALED']] = standard_scaler.fit_transform(data[['LATITUDE', 'LONGITUDE']])

# Drop orginal features
data = data.drop(columns=[
    'PROPERTYSQFT', 'BATH', 'BEDS',
    'ZIP_CODE', 'LATITUDE', 'LONGITUDE',
    'PROPERTYSQFT_LOG', 'BATH_LOG'
  ])

### PREVIEW PREPROCESSED SUPERVISED LEARNING DATASET
data.head()

data.columns

### BUIDLING THE BASELINE ML MODEL

# Define X and y
X = data.drop(columns=['PRICE'])
y = data['PRICE']

# Split the data
X_train, X_test, y_train, y_test_baseline = train_test_split(X, y, test_size=0.2, random_state=42)

# Define base models
rf = RandomForestRegressor(n_estimators=100, random_state=42)
gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
ridge = Ridge(alpha=1.0)

# Create an ensemble using VotingRegressor
ensemble = VotingRegressor(estimators=[
    ('rf', rf),
    ('gbr', gbr),
    ('ridge', ridge)
])

# Fit the ensemble model
ensemble.fit(X_train, y_train)

# Predict and evaluate
y_pred_baseline = ensemble.predict(X_test)
mae = mean_absolute_error(y_test_baseline, y_pred_baseline)
rmse = np.sqrt(mean_squared_error(y_test_baseline, y_pred_baseline))
r2 = r2_score(y_test_baseline, y_pred_baseline)

mae, rmse, r2

### PLOT MODEL RESULTS

import matplotlib.pyplot as plt

# Scatter plot of actual vs predicted prices
plt.figure(figsize=(10, 6))
plt.scatter(y_test_baseline, y_pred_baseline, alpha=0.4)
plt.plot([y_test_baseline.min(), y_test_baseline.max()], [y_test_baseline.min(), y_test_baseline.max()], '--r', linewidth=2)
plt.title("Actual vs Predicted Prices")
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.grid(True)
plt.tight_layout()
plt.show()

### ZOOM IN ON AREAS OF THE PLOT

# Define price ranges
ranges = {
    "Cheaper Homes (Under $1M)": (0, 1_000_000),
    "Mid-Priced Homes ($1M - $5M)": (1_000_000, 5_000_000),
    "Expensive Homes (Over $5M)": (5_000_000, y_test_baseline.max())
}

# Plot each range separately
plt.figure(figsize=(18, 5))

for i, (label, (low, high)) in enumerate(ranges.items(), 1):
    mask = (y_test_baseline >= low) & (y_test_baseline < high)
    plt.subplot(1, 3, i)
    plt.scatter(y_test_baseline[mask], y_pred_baseline[mask], alpha=0.4)
    plt.plot([low, high], [low, high], '--r', linewidth=2)
    plt.title(label)
    plt.xlabel("Actual Price")
    plt.ylabel("Predicted Price")
    plt.grid(True)

plt.tight_layout()
plt.show()

### CLUSTERING THE FURTHER DATA

# Helper function to visualize clusters using PCA
def plot_clusters(tfidf_matrix, labels, title):
    pca = PCA(n_components=2)
    reduced = pca.fit_transform(tfidf_matrix.toarray())
    plt.figure(figsize=(6, 5))
    scatter = plt.scatter(reduced[:, 0], reduced[:, 1], c=labels, cmap='tab10', alpha=0.6)
    plt.title(f"{title} Clustering (PCA Projection)")
    plt.xlabel("PCA 1")
    plt.ylabel("PCA 2")
    plt.colorbar(scatter)
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Function that also returns the TF-IDF matrix for plotting
def cluster_and_plot(df, column_name, n_clusters=10):
    texts = df[column_name].fillna("missing").astype(str)
    vectorizer = TfidfVectorizer(max_features=100, stop_words='english')
    tfidf_matrix = vectorizer.fit_transform(texts)

    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    labels = kmeans.fit_predict(tfidf_matrix)

    cluster_col_name = f"{column_name}_CLUSTER"
    df[cluster_col_name] = labels

    plot_clusters(tfidf_matrix, labels, column_name)

    return df, cluster_col_name

# Columns to cluster
columns_to_cluster = [
    'BROKERTITLE',
    'ADDRESS',
    'ADMINISTRATIVE_AREA_LEVEL_2',
    'LOCALITY',
    'SUBLOCALITY',
    'STREET_NAME'
]

columns_to_add = [
    'BROKERTITLE',
    'ADDRESS',
    'ADMINISTRATIVE_AREA_LEVEL_2',
    'LOCALITY',
    'SUBLOCALITY',
    'STREET_NAME'
]

# Merge them back into your new DataFrame
clustered_df = pd.concat([data, og_df[columns_to_cluster].reset_index(drop=True)], axis=1)

for col in columns_to_cluster:
    clustered_df, _ = cluster_and_plot(clustered_df, col, n_clusters=10)

### EVALUATE CLUSTERING PERFORMANCES

# Function to compute silhouette score for a column's clustering
def evaluate_clustering_quality(df, column_name, n_clusters=10):
    texts = df[column_name].fillna("missing").astype(str)
    vectorizer = TfidfVectorizer(max_features=100, stop_words='english')
    tfidf_matrix = vectorizer.fit_transform(texts)

    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    labels = kmeans.fit_predict(tfidf_matrix)

    # Compute silhouette score
    if len(set(labels)) > 1:  # Silhouette score requires >1 cluster
        score = silhouette_score(tfidf_matrix, labels)
    else:
        score = np.nan
    return score

# Evaluate all clustered columns
cluster_scores = {}
for col in columns_to_cluster:
    score = evaluate_clustering_quality(og_df, col, n_clusters=10)
    cluster_scores[col] = score

# Create and show the results as a DataFrame
scores_df = pd.DataFrame.from_dict(cluster_scores, orient='index', columns=['Silhouette Score'])
scores_df = scores_df.sort_values(by='Silhouette Score', ascending=False)
scores_df

### ADD CLUSTERED DATA FEATURES BACK INTO DF

# Select strong cluster columns based on silhouette score (> 0.7)
strong_cluster_cols = [
    'LOCALITY_CLUSTER',
    'ADMINISTRATIVE_AREA_LEVEL_2_CLUSTER',
    'SUBLOCALITY_CLUSTER',
    'STREET_NAME_CLUSTER'
]

# One-hot encode these strong cluster columns
cluster_dummies = pd.get_dummies(clustered_df[strong_cluster_cols],
                                 columns=strong_cluster_cols,
                                 prefix=strong_cluster_cols,
                                 drop_first=True)

# Join back to the original DataFrame
final_clustered_df = pd.concat([clustered_df, cluster_dummies], axis=1)

# Drop original strong cluster columns after encoding
final_clustered_df.drop(columns=strong_cluster_cols, inplace=True)

# Drop weak cluster columns and ogs
final_clustered_df.drop(columns=['BROKERTITLE', 'ADDRESS', 'LOCALITY', 'ADMINISTRATIVE_AREA_LEVEL_2',
       'SUBLOCALITY', 'STREET_NAME', 'BROKERTITLE_CLUSTER', 'ADDRESS_CLUSTER'], inplace=True)

# Preview final structure
final_clustered_df.head()

final_clustered_df.columns

### RETRAIN MODEL ON NEW DATASET INLUDING THE CLUSTERED FEATURES

model_df = final_clustered_df

# Define X and y
X = model_df.drop(columns=['PRICE'])
y = model_df['PRICE']

# Split into train/test sets
X_train, X_test, y_train, y_test_enhanced = train_test_split(X, y, test_size=0.2, random_state=42)

# Define base models
rf = RandomForestRegressor(n_estimators=100, random_state=42)
gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
ridge = Ridge(alpha=1.0)

# Ensemble model
ensemble = VotingRegressor(estimators=[
    ('rf', rf),
    ('gbr', gbr),
    ('ridge', ridge)
])

# Train ensemble
ensemble.fit(X_train, y_train)

# Predict and evaluate
y_pred_enhanced = ensemble.predict(X_test)
mae = mean_absolute_error(y_test_enhanced, y_pred_enhanced)
rmse = np.sqrt(mean_squared_error(y_test_enhanced, y_pred_enhanced))
r2 = r2_score(y_test_enhanced, y_pred_enhanced)

mae, rmse, r2

### PLOT ENHANCED MODEL RESULTS

# Scatter plot of actual vs predicted prices
plt.figure(figsize=(10, 6))
plt.scatter(y_test_enhanced, y_pred_enhanced, alpha=0.4)
plt.plot([y_test_enhanced.min(), y_test_enhanced.max()], [y_test_enhanced.min(), y_test_enhanced.max()], '--r', linewidth=2)
plt.title("Actual vs Predicted Prices")
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.grid(True)
plt.tight_layout()
plt.show()

### ZOOM IN ON AREAS OF THE PLOT

# Define price ranges
ranges = {
    "Cheaper Homes (Under $1M)": (0, 1_000_000),
    "Mid-Priced Homes ($1M - $5M)": (1_000_000, 5_000_000),
    "Expensive Homes (Over $5M)": (5_000_000, y_test_enhanced.max())
}

# Plot each range separately
plt.figure(figsize=(18, 5))

for i, (label, (low, high)) in enumerate(ranges.items(), 1):
    mask = (y_test_enhanced >= low) & (y_test_enhanced < high)
    plt.subplot(1, 3, i)
    plt.scatter(y_test_enhanced[mask], y_pred_enhanced[mask], alpha=0.4)
    plt.plot([low, high], [low, high], '--r', linewidth=2)
    plt.title(label)
    plt.xlabel("Actual Price")
    plt.ylabel("Predicted Price")
    plt.grid(True)

plt.tight_layout()
plt.show()

### COMPUTE SHAP VALS

"""
SHAP values represent how much each feature contributes to pushing a prediction above or below the baseline (expected value).
"""

import shap

# Sample subset and convert all features to float
X_sample = X_test.sample(200, random_state=42).astype(float)
X_train_float = X_train.astype(float)

# Create SHAP explainer
explainer = shap.Explainer(ensemble.predict, X_train_float)

# Compute SHAP values
shap_values = explainer(X_sample)

# Plot summary
shap.plots.beeswarm(shap_values)

### CONDUCTING A THOROUGH STATISTICAL ANALYSIS COMPARING BOTH MODELS

# Calculate residuals
residuals_baseline = y_test_baseline - y_pred_baseline
residuals_enhanced = y_test_enhanced - y_pred_enhanced

# Performance metrics
metrics = {
    "MAE": [
        mean_absolute_error(y_test_baseline, y_pred_baseline),
        mean_absolute_error(y_test_enhanced, y_pred_enhanced)
    ],
    "RMSE": [
        np.sqrt(mean_squared_error(y_test_baseline, y_pred_baseline)),
        np.sqrt(mean_squared_error(y_test_enhanced, y_pred_enhanced))
    ],
    "R²": [
        r2_score(y_test_baseline, y_pred_baseline),
        r2_score(y_test_enhanced, y_pred_enhanced)
    ]
}

metrics_df = pd.DataFrame(metrics, index=["Baseline", "Clustered"])
print("Model Performance Comparison:")
display(metrics_df)

# T-test: Are the residuals significantly different?
t_stat, p_val = ttest_rel(np.abs(residuals_baseline), np.abs(residuals_enhanced))
print(f"\nPaired t-test on absolute errors:")
print(f"T-statistic = {t_stat:.4f}, p-value = {p_val:.4f}")
if p_val < 0.05:
    print("The improvement is statistically significant.")
else:
    print("The improvement is NOT statistically significant.")

# --- Visual Comparisons ---
plt.figure(figsize=(16, 10))

# 1. Residual Distribution
plt.subplot(2, 2, 1)
sns.histplot(residuals_baseline, color='red', label='Baseline', kde=True)
sns.histplot(residuals_enhanced, color='green', label='Clustered', kde=True)
plt.title("Distribution of Residuals")
plt.xlabel("Residuals")
plt.legend()

# 2. Residual Scatter
plt.subplot(2, 2, 2)
plt.scatter(y_test_baseline, residuals_baseline, alpha=0.4, label='Baseline', color='red')
plt.scatter(y_test_enhanced, residuals_enhanced, alpha=0.4, label='Clustered', color='green')
plt.axhline(0, linestyle='--', color='black')
plt.title("Residuals vs Actual Prices")
plt.xlabel("Actual Price")
plt.ylabel("Residual")
plt.legend()

# 3. Error Comparison Histogram
plt.subplot(2, 2, 3)
error_baseline = np.abs(residuals_baseline)
error_enhanced = np.abs(residuals_enhanced)
sns.histplot(error_baseline, bins=40, color='red', label='Baseline', alpha=0.5)
sns.histplot(error_enhanced, bins=40, color='green', label='Clustered', alpha=0.5)
plt.title("Absolute Errors Distribution")
plt.xlabel("Absolute Error")
plt.legend()

# 4. Boxplot of absolute errors
plt.subplot(2, 2, 4)
sns.boxplot(data=[error_baseline, error_enhanced], palette=['red', 'green'])
plt.xticks([0, 1], ['Baseline', 'Clustered'])
plt.title("Absolute Error Comparison")

plt.tight_layout()
plt.show()

"""# NYC Housing Price Prediction Project — One-Pager Summary

## Objective
The goal of this project was to build a robust machine learning pipeline to predict NYC housing prices using a diverse set of property features. Beyond baseline modeling, the project introduces unsupervised clustering of textual location features to assess their impact on model performance.

### 1. Data Cleaning & Preprocessing
Dataset: A real-world housing dataset containing ~24,000 listings with address, pricing, property features, and brokerage information.
Text Parsing: ZIP codes were extracted from the STATE column to map each listing to one of NYC’s five boroughs using custom logic.
Encoding: Categorical features like TYPE and BOROUGH were one-hot encoded.
Feature Selection: Redundant text-heavy columns (e.g., FORMATTED_ADDRESS, BROKERTITLE) were dropped to streamline modeling.
Scaling: Numerical features were transformed:
Log Transformation for skewed data (e.g., PROPERTYSQFT, BATH)
RobustScaler for outlier-resistant scaling
StandardScaler for geographical features (LATITUDE, LONGITUDE)
### 2. Baseline Ensemble Model
Model Type: A VotingRegressor ensemble combining:
* RandomForestRegressor
* GradientBoostingRegressor
* Ridge Regression

Performance:
* MAE: $1.57M

* RMSE: $3.50M

* R²: 0.51

Insights: The model performed reasonably well on mid-range properties, but struggled with extremes—particularly underpredicting expensive homes.
### 3. Feature Engineering via Text Clustering
Motivation: Text fields like `BROKERTITLE`, `LOCALITY`, and `STREET_NAME` contain valuable geographic and brokerage-related signal, but are high cardinality and unstructured.
Method:
Used TF-IDF vectorization on each field
Applied KMeans clustering (k=10) to group similar entries
Dimensionality reduction via PCA for 2D visual inspection
Evaluation: Silhouette scores guided selection of strong clusters (e.g., `LOCALITY`, `SUBLOCALITY`, `STREET_NAME`)
Integration: High-quality clusters were one-hot encoded and added to the dataset, replacing original raw fields
### 4. Enhanced Model with Clustering Features
Retrained the same ensemble on the new feature set

Performance:

* MAE: $1.56M

* RMSE: $3.41M

* R²: 0.54

SHAP Analysis: Confirmed increased importance of engineered features like `STREET_NAME_CLUSTER` and `LOCALITY_CLUSTER`
### 5. Evaluation & Statistical Comparison
Compared both models via:
Residual distributions
Error boxplots
Price-segmented visualizations
Paired T-test on absolute errors:
p-value = 0.9605 → Improvement not statistically significant
Conclusion: While clustering added nuance and slightly improved performance, gains were subtle and model bias toward luxury listings remains a challenge.
### Key Takeaways
Feature engineering from unstructured text can meaningfully improve predictive models.
Ensemble methods yield strong baseline results, but interpretability tools like SHAP are critical for validation.
Statistical testing is essential to confirm whether observed improvements are real or noise.
"""



























